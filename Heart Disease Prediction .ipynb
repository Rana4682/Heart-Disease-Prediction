{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ccfa270-7cdb-47c4-bdcc-3d0155239d2c",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "95aef676-94b9-4f4f-9106-27645b0c8154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bf0acf65-f8b2-431b-bcf4-2a6d0af36b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets_4123_6408_framingham (1).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3d3ad9de-6427-48ee-9983-82a3a0cebbce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   male  age  education  currentSmoker  cigsPerDay  BPMeds  prevalentStroke  \\\n",
       "0     1   39        4.0              0         0.0     0.0                0   \n",
       "1     0   46        2.0              0         0.0     0.0                0   \n",
       "2     1   48        1.0              1        20.0     0.0                0   \n",
       "3     0   61        3.0              1        30.0     0.0                0   \n",
       "4     0   46        3.0              1        23.0     0.0                0   \n",
       "\n",
       "   prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  heartRate  glucose  \\\n",
       "0             0         0    195.0  106.0   70.0  26.97       80.0     77.0   \n",
       "1             0         0    250.0  121.0   81.0  28.73       95.0     76.0   \n",
       "2             0         0    245.0  127.5   80.0  25.34       75.0     70.0   \n",
       "3             1         0    225.0  150.0   95.0  28.58       65.0    103.0   \n",
       "4             0         0    285.0  130.0   84.0  23.10       85.0     85.0   \n",
       "\n",
       "   TenYearCHD  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           1  \n",
       "4           0  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fb1791b7-21f9-4d66-8559-bff94b4fe67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.drop(columns=['education'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d09915-00d0-4919-a801-4fcfb4b79968",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5dd3a533-cd99-41a4-a21d-536a88705047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male                 0\n",
       "age                  0\n",
       "currentSmoker        0\n",
       "cigsPerDay          29\n",
       "BPMeds              53\n",
       "prevalentStroke      0\n",
       "prevalentHyp         0\n",
       "diabetes             0\n",
       "totChol             50\n",
       "sysBP                0\n",
       "diaBP                0\n",
       "BMI                 19\n",
       "heartRate            1\n",
       "glucose            388\n",
       "TenYearCHD           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "385551e5-e516-4cd6-a48d-733bfd419863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4240, 15)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262b6213-d3a1-4b83-90d1-8449449f211c",
   "metadata": {},
   "source": [
    "## Fill Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "85ec1eeb-5dff-4f49-ab9c-38df0965bbc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_14264\\844255492.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(mode_val, inplace=True)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_14264\\844255492.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(mode_val, inplace=True)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_14264\\844255492.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(mode_val, inplace=True)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_14264\\844255492.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(mode_val, inplace=True)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_14264\\844255492.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(mode_val, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Define the binary columns\n",
    "bin_cols = [\"male\", \"currentSmoker\", \"prevalentStroke\", \"prevalentHyp\", \"diabetes\"]\n",
    "\n",
    "# Fill missing values for binary features with the most frequent value (mode)\n",
    "for col in bin_cols:\n",
    "    mode_val = df[col].mode()[0]\n",
    "    df[col].fillna(mode_val, inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0e5296b0-c43f-4693-8c11-28927577a461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are any remaining missing values\n",
    "missing_values = df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a1efa1e3-7b7e-43db-8b8d-9d8de30b6df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male                 0\n",
       "age                  0\n",
       "currentSmoker        0\n",
       "cigsPerDay          29\n",
       "BPMeds              53\n",
       "prevalentStroke      0\n",
       "prevalentHyp         0\n",
       "diabetes             0\n",
       "totChol             50\n",
       "sysBP                0\n",
       "diaBP                0\n",
       "BMI                 19\n",
       "heartRate            1\n",
       "glucose            388\n",
       "TenYearCHD           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "51cf0857-96b0-48d2-9a30-576d2245bb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_14264\\279335499.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_14264\\279335499.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_14264\\279335499.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_14264\\279335499.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_14264\\279335499.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_14264\\279335499.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(median_val, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "\n",
    "# Fill missing values for numeric features\n",
    "numeric_cols = [\"cigsPerDay\", \"BPMeds\", \"totChol\", \"BMI\", \"heartRate\", \"glucose\"]\n",
    "for col in numeric_cols:\n",
    "    median_val = df[col].median()\n",
    "    df[col].fillna(median_val, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3047fbb6-de3d-4b42-9b05-d8ee914966b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are any remaining missing values\n",
    "missing_values = df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9c19ae85-6de0-40f5-b2b9-76f420fe118e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male               0\n",
       "age                0\n",
       "currentSmoker      0\n",
       "cigsPerDay         0\n",
       "BPMeds             0\n",
       "prevalentStroke    0\n",
       "prevalentHyp       0\n",
       "diabetes           0\n",
       "totChol            0\n",
       "sysBP              0\n",
       "diaBP              0\n",
       "BMI                0\n",
       "heartRate          0\n",
       "glucose            0\n",
       "TenYearCHD         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af8aab9-5c0f-4159-b0f1-b8e66720769c",
   "metadata": {},
   "source": [
    "## Balance Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9eb5b95a-d295-49f8-a244-6c4fd6221932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TenYearCHD\n",
       "0    3596\n",
       "1     644\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['TenYearCHD'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b724c854-dce8-441b-8711-f48ed1fd86f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Separate majority and minority classes\n",
    "df_majority = df[df['TenYearCHD'] == 0]\n",
    "df_minority = df[df['TenYearCHD'] == 1]\n",
    "\n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # Sample with replacement\n",
    "                                 n_samples=len(df_majority),    # To match majority class\n",
    "                                 random_state=42) # Reproducible results\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "df_balanced = pd.concat([df_majority, df_minority_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "999a8910-4809-4fe0-8d9a-b2caca05b427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TenYearCHD\n",
       "0    3596\n",
       "1    3596\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced['TenYearCHD'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd92fa9-094b-4178-8db6-2741fedd6284",
   "metadata": {},
   "source": [
    "## Train Test Split and Feature Scalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b9253ef3-a904-4f8b-a1ba-b5c9a54b149e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = df_balanced.drop(columns=['TenYearCHD'])\n",
    "y = df_balanced['TenYearCHD']\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a51ad3-59dd-4a8f-895c-dce5e5ae76ce",
   "metadata": {},
   "source": [
    "## Scaling (StandardScale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "947a6b4e-9eb6-483b-9b00-87c4ec185171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit scaler to training data and transform both training and testing data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7cca3f-2f1c-4d39-a6e7-cd8b7c11ef02",
   "metadata": {},
   "source": [
    "## Training 10 Models With Different Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9dd15fd7-a8f0-4e18-818d-1f4126d91bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier Accuracy: 0.9763724808895066\n",
      "Classification Report for RandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98       735\n",
      "           1       0.96      0.99      0.98       704\n",
      "\n",
      "    accuracy                           0.98      1439\n",
      "   macro avg       0.98      0.98      0.98      1439\n",
      "weighted avg       0.98      0.98      0.98      1439\n",
      "\n",
      "Confusion Matrix for RandomForestClassifier:\n",
      "[[706  29]\n",
      " [  5 699]]\n",
      "==================================================\n",
      "AdaBoostClassifier Accuracy: 0.6518415566365532\n",
      "Classification Report for AdaBoostClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.61      0.64       735\n",
      "           1       0.63      0.70      0.66       704\n",
      "\n",
      "    accuracy                           0.65      1439\n",
      "   macro avg       0.65      0.65      0.65      1439\n",
      "weighted avg       0.65      0.65      0.65      1439\n",
      "\n",
      "Confusion Matrix for AdaBoostClassifier:\n",
      "[[447 288]\n",
      " [213 491]]\n",
      "==================================================\n",
      "GradientBoostingClassifier Accuracy: 0.7289784572619875\n",
      "Classification Report for GradientBoostingClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.69      0.72       735\n",
      "           1       0.70      0.77      0.74       704\n",
      "\n",
      "    accuracy                           0.73      1439\n",
      "   macro avg       0.73      0.73      0.73      1439\n",
      "weighted avg       0.73      0.73      0.73      1439\n",
      "\n",
      "Confusion Matrix for GradientBoostingClassifier:\n",
      "[[508 227]\n",
      " [163 541]]\n",
      "==================================================\n",
      "LogisticRegression Accuracy: 0.6587908269631688\n",
      "Classification Report for LogisticRegression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.65      0.66       735\n",
      "           1       0.65      0.66      0.66       704\n",
      "\n",
      "    accuracy                           0.66      1439\n",
      "   macro avg       0.66      0.66      0.66      1439\n",
      "weighted avg       0.66      0.66      0.66      1439\n",
      "\n",
      "Confusion Matrix for LogisticRegression:\n",
      "[[481 254]\n",
      " [237 467]]\n",
      "==================================================\n",
      "SVC Accuracy: 0.6831132731063239\n",
      "Classification Report for SVC:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.67      0.68       735\n",
      "           1       0.67      0.70      0.68       704\n",
      "\n",
      "    accuracy                           0.68      1439\n",
      "   macro avg       0.68      0.68      0.68      1439\n",
      "weighted avg       0.68      0.68      0.68      1439\n",
      "\n",
      "Confusion Matrix for SVC:\n",
      "[[493 242]\n",
      " [214 490]]\n",
      "==================================================\n",
      "KNeighborsClassifier Accuracy: 0.7873523280055594\n",
      "Classification Report for KNeighborsClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.66      0.76       735\n",
      "           1       0.72      0.92      0.81       704\n",
      "\n",
      "    accuracy                           0.79      1439\n",
      "   macro avg       0.81      0.79      0.78      1439\n",
      "weighted avg       0.81      0.79      0.78      1439\n",
      "\n",
      "Confusion Matrix for KNeighborsClassifier:\n",
      "[[482 253]\n",
      " [ 53 651]]\n",
      "==================================================\n",
      "DecisionTreeClassifier Accuracy: 0.9186935371785963\n",
      "Classification Report for DecisionTreeClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.84      0.91       735\n",
      "           1       0.86      1.00      0.92       704\n",
      "\n",
      "    accuracy                           0.92      1439\n",
      "   macro avg       0.93      0.92      0.92      1439\n",
      "weighted avg       0.93      0.92      0.92      1439\n",
      "\n",
      "Confusion Matrix for DecisionTreeClassifier:\n",
      "[[621 114]\n",
      " [  3 701]]\n",
      "==================================================\n",
      "GaussianNB Accuracy: 0.5830437804030577\n",
      "Classification Report for GaussianNB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.91      0.69       735\n",
      "           1       0.72      0.24      0.36       704\n",
      "\n",
      "    accuracy                           0.58      1439\n",
      "   macro avg       0.64      0.58      0.53      1439\n",
      "weighted avg       0.64      0.58      0.53      1439\n",
      "\n",
      "Confusion Matrix for GaussianNB:\n",
      "[[668  67]\n",
      " [533 171]]\n",
      "==================================================\n",
      "XGBClassifier Accuracy: 0.906184850590688\n",
      "Classification Report for XGBClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.85      0.90       735\n",
      "           1       0.86      0.96      0.91       704\n",
      "\n",
      "    accuracy                           0.91      1439\n",
      "   macro avg       0.91      0.91      0.91      1439\n",
      "weighted avg       0.91      0.91      0.91      1439\n",
      "\n",
      "Confusion Matrix for XGBClassifier:\n",
      "[[625 110]\n",
      " [ 25 679]]\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# Define a list of classifiers\n",
    "classifiers = [\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    LogisticRegression(),\n",
    "    SVC(),\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    GaussianNB(),\n",
    "    XGBClassifier()\n",
    "]\n",
    "\n",
    "# Create a dictionary to store the results\n",
    "results = {}\n",
    "\n",
    "\n",
    "# Train and evaluate each classifier\n",
    "for clf in classifiers:\n",
    "    clf_name = clf.__class__.__name__\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "    y_pred = clf.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{clf_name} Accuracy: {accuracy}\")\n",
    "    \n",
    "    # Classification report\n",
    "    print(f\"Classification Report for {clf_name}:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Confusion matrix\n",
    "    print(f\"Confusion Matrix for {clf_name}:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dad053f-aa13-4ca7-9a58-31202277a8b0",
   "metadata": {},
   "source": [
    " ## Show Each Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d583f545-96a1-4575-b263-30307a037a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_14264\\190865209.py:49: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.974983</td>\n",
       "      <td>0.974984</td>\n",
       "      <td>0.975622</td>\n",
       "      <td>0.974983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.651842</td>\n",
       "      <td>0.651286</td>\n",
       "      <td>0.654290</td>\n",
       "      <td>0.651842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.728978</td>\n",
       "      <td>0.728702</td>\n",
       "      <td>0.731320</td>\n",
       "      <td>0.728978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.658791</td>\n",
       "      <td>0.658830</td>\n",
       "      <td>0.659053</td>\n",
       "      <td>0.658791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.683113</td>\n",
       "      <td>0.683126</td>\n",
       "      <td>0.683656</td>\n",
       "      <td>0.683113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.787352</td>\n",
       "      <td>0.783833</td>\n",
       "      <td>0.812481</td>\n",
       "      <td>0.787352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.920778</td>\n",
       "      <td>0.920459</td>\n",
       "      <td>0.930679</td>\n",
       "      <td>0.920778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.583044</td>\n",
       "      <td>0.530092</td>\n",
       "      <td>0.635597</td>\n",
       "      <td>0.583044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.906185</td>\n",
       "      <td>0.905977</td>\n",
       "      <td>0.912148</td>\n",
       "      <td>0.906185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  Accuracy  F1-Score  Precision    Recall\n",
       "0      RandomForestClassifier  0.974983  0.974984   0.975622  0.974983\n",
       "1          AdaBoostClassifier  0.651842  0.651286   0.654290  0.651842\n",
       "2  GradientBoostingClassifier  0.728978  0.728702   0.731320  0.728978\n",
       "3          LogisticRegression  0.658791  0.658830   0.659053  0.658791\n",
       "4                         SVC  0.683113  0.683126   0.683656  0.683113\n",
       "5        KNeighborsClassifier  0.787352  0.783833   0.812481  0.787352\n",
       "6      DecisionTreeClassifier  0.920778  0.920459   0.930679  0.920778\n",
       "7                  GaussianNB  0.583044  0.530092   0.635597  0.583044\n",
       "8               XGBClassifier  0.906185  0.905977   0.912148  0.906185"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Define a list of classifiers\n",
    "classifiers = [\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    LogisticRegression(),\n",
    "    SVC(),\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    GaussianNB(),\n",
    "    XGBClassifier()\n",
    "]\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Accuracy', 'F1-Score', 'Precision', 'Recall'])\n",
    "\n",
    "# Train and evaluate each classifier\n",
    "for clf in classifiers:\n",
    "    clf_name = clf.__class__.__name__\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "    y_pred = clf.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    f1_score = report['weighted avg']['f1-score']\n",
    "    precision = report['weighted avg']['precision']\n",
    "    recall = report['weighted avg']['recall']\n",
    "    \n",
    "  \n",
    "    new_row = pd.DataFrame([{\n",
    "        'Model': clf_name,\n",
    "        'Accuracy': accuracy,\n",
    "        'F1-Score': f1_score,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall\n",
    "    }])\n",
    "    \n",
    "    results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48776b57-4112-4ec6-94b5-b4815f7aa6ec",
   "metadata": {},
   "source": [
    "## Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3801813a-753b-412b-a5d6-d73f3fe8c156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Accuracy: 0.9742876997915219\n",
      "Classification Report for Random Forest Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97       735\n",
      "           1       0.96      0.99      0.97       704\n",
      "\n",
      "    accuracy                           0.97      1439\n",
      "   macro avg       0.97      0.97      0.97      1439\n",
      "weighted avg       0.97      0.97      0.97      1439\n",
      "\n",
      "Confusion Matrix for Random Forest Classifier:\n",
      "[[703  32]\n",
      " [  5 699]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Instantiate the RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# Train the RandomForestClassifier\n",
    "rf_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_rf = rf_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(\"Random Forest Classifier Accuracy:\", accuracy_rf)\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report for Random Forest Classifier:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"Confusion Matrix for Random Forest Classifier:\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc583e0-ab45-4314-ab77-8b93bfbfbf37",
   "metadata": {},
   "source": [
    "## Single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6f03b914-1e09-41bb-a519-71ab4a190e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predcted class  0\n",
      "actual class  0\n"
     ]
    }
   ],
   "source": [
    "# test 1:\n",
    "print(\"predcted class \",rf_classifier.predict(X_test_scaled[10].reshape(1,-1))[0])\n",
    "print(\"actual class \", y_test.iloc[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6e60396a-1586-4a68-ae0c-a2eadd9e3a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predcted class  1\n",
      "actual class  1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# test 2:\n",
    "print(\"predcted class \",rf_classifier.predict(X_test_scaled[200].reshape(1,-1))[0])\n",
    "print(\"actual class \", y_test.iloc[200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1ff5e87b-e20f-4d45-872f-5583244b950d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predcted class  1\n",
      "actual class  1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# test 3:\n",
    "print(\"predcted class \",rf_classifier.predict(X_test_scaled[110].reshape(1,-1))[0])\n",
    "print(\"actual class \", y_test.iloc[110])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db48f5a-bb30-4c46-9f81-3a8dfd23219f",
   "metadata": {},
   "source": [
    "## Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ece3c385-06be-47e1-ad1f-d871416ccc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(rf_classifier,open(\"Model/rf_classifier.pkl\",'wb'))\n",
    "pickle.dump(scaler,open(\"Model/scaler.pkl\",'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a0e811-5553-4bce-ba28-36306796e859",
   "metadata": {},
   "source": [
    "## Load models to test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "39e27056-96da-49bb-8bc1-4b5ab96fd06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load models to test1\n",
    "import pickle\n",
    "\n",
    "# Load the RandomForestClassifier model\n",
    "with open(\"Model/rf_classifier.pkl\", \"rb\") as file:\n",
    "    rf_classifier = pickle.load(file)\n",
    "\n",
    "# Load the scaler\n",
    "with open(\"Model/scaler.pkl\", \"rb\") as file:\n",
    "    scaler = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61644a37-2355-4047-a013-7fa838a4850c",
   "metadata": {},
   "source": [
    "## Predictive System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f774934d-d4a9-4b0c-b5ea-a2f023a971ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def predict(model, scaler, male, age, currentSmoker, cigsPerDay, BPMeds, prevalentStroke, prevalentHyp, diabetes, totChol, sysBP, diaBP, BMI, heartRate, glucose):\n",
    "    # Encode categorical variables\n",
    "    male_encoded = 1 if male.lower() == \"male\" else 0\n",
    "    currentSmoker_encoded = 1 if currentSmoker.lower() == \"yes\" else 0\n",
    "    BPMeds_encoded = 1 if BPMeds.lower() == \"yes\" else 0\n",
    "    prevalentStroke_encoded = 1 if prevalentStroke.lower() == \"yes\" else 0\n",
    "    prevalentHyp_encoded = 1 if prevalentHyp.lower() == \"yes\" else 0\n",
    "    diabetes_encoded = 1 if diabetes.lower() == \"yes\" else 0\n",
    "    \n",
    "    # Prepare features array\n",
    "    features = np.array([[male_encoded, age, currentSmoker_encoded, cigsPerDay, BPMeds_encoded, prevalentStroke_encoded, prevalentHyp_encoded, diabetes_encoded, totChol, sysBP, diaBP, BMI, heartRate, glucose]])\n",
    "    \n",
    "    # scalling\n",
    "    scaled_features = scaler.transform(features)\n",
    "    \n",
    "    # predict by model\n",
    "    result = model.predict(scaled_features)\n",
    "    \n",
    "    return result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c11d5f48-3f6c-4fbc-9e4e-b14ce6892d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Patiennt has No Heart Deseas\n"
     ]
    }
   ],
   "source": [
    "# test 1:\n",
    "male = \"female\"\n",
    "age = 56.00\n",
    "currentSmoker = \"yes\"\n",
    "cigsPerDay = 3.00\n",
    "BPMeds = \"no\"\n",
    "prevalentStroke = \"no\"\n",
    "prevalentHyp = \"yes\"\n",
    "diabetes = 'no'\n",
    "totChol = 285.00\n",
    "sysBP = 145.00\n",
    "diaBP = 100.00\n",
    "BMI = 30.14\n",
    "heartRate = 80.00\n",
    "glucose = 86.00\n",
    "\n",
    "\n",
    "result = predict(rf_classifier, scaler, male, age, currentSmoker, cigsPerDay, BPMeds, prevalentStroke, prevalentHyp, diabetes, totChol, sysBP, diaBP, BMI, heartRate, glucose)\n",
    "\n",
    "\n",
    "if result == 1:\n",
    "    print(\"The Patient has Heart Diseas\")\n",
    "else: \n",
    "    print(\"The Patiennt has No Heart Deseas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0e56daf9-10c1-4c08-a6af-f441182d29d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Patient has Heart Diseas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "male = 'female'\n",
    "age = 63.0\n",
    "currentSmoker = 'yes'\n",
    "cigsPerDay = 3.0\n",
    "BPMeds = 'no'\n",
    "prevalentStroke = 'no'\n",
    "prevalentHyp = 'yes'\n",
    "diabetes = 'no'\n",
    "totChol = 267.0\n",
    "sysBP = 156.5\n",
    "diaBP = 92.5\n",
    "BMI = 27.1\n",
    "heartRate = 60.0\n",
    "glucose = 79.0\n",
    "result = 1.0\n",
    "\n",
    "\n",
    "\n",
    "result = predict(rf_classifier, scaler, male, age, currentSmoker, cigsPerDay, BPMeds, prevalentStroke, prevalentHyp, diabetes, totChol, sysBP, diaBP, BMI, heartRate, glucose)\n",
    "\n",
    "\n",
    "if result == 1:\n",
    "    print(\"The Patient has Heart Diseas\")\n",
    "else: \n",
    "    print(\"The Patiennt has No Heart Deseas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f059935a-1d0e-4608-98bd-dff3191acb7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.1'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fd04a489-1f5a-43ae-8612-382fa5e134d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
